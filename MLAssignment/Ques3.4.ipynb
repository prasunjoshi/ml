{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy.linalg import inv\n",
    "from sklearn.metrics import accuracy_score , precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read csv file into DataFrame\n",
    "Parameters: Path of csv file\n",
    "Returns: Pandas DataFrame \n",
    "\"\"\"  \n",
    "def load_data(csv_path):\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2254 entries, 0 to 2253\n",
      "Data columns (total 8 columns):\n",
      "Unnamed: 0    2254 non-null int64\n",
      "1             2254 non-null float64\n",
      "2             2254 non-null float64\n",
      "3             2254 non-null float64\n",
      "4             2254 non-null float64\n",
      "5             2254 non-null float64\n",
      "6             2254 non-null float64\n",
      "7             2254 non-null int64\n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 141.0 KB\n"
     ]
    }
   ],
   "source": [
    "#load D9.csv into dataframe object\n",
    "q3 = load_data(\"dataset/D9.csv\")\n",
    "\n",
    "#have a look at the info of the data\n",
    "q3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the unnamed column as 'id'\n",
    "q3.rename(columns={'Unnamed: 0':'id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no. of features\n",
    "n = 6 \n",
    "m = q3.shape[0]\n",
    "\n",
    "X = np.ones((m,n + 1))\n",
    "y = np.array((m,1))\n",
    "\n",
    "X[:,1] = q3['1'].values\n",
    "X[:,2] = q3['2'].values\n",
    "X[:,3] = q3['3'].values\n",
    "X[:,4] = q3['4'].values\n",
    "X[:,5] = q3['5'].values\n",
    "X[:,6] = q3['6'].values\n",
    "\n",
    "#Store Labels\n",
    "y = q3['7'].values\n",
    "\n",
    "#Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 11)\n",
    "\n",
    "#Store species labels\n",
    "class_labels = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "#Calculate Hessian matrix and it's inverse\n",
    "theta_mat = np.random.randn(7,1)\n",
    "p_x = sigmoid(X_train.dot(theta_mat))\n",
    "p_x_transpose = (1-p_x).T\n",
    "\n",
    "W = p_x.dot(p_x_transpose)\n",
    "np.shape(W)\n",
    "\n",
    "for i in range(len(W)):\n",
    "    for j in range(len(W)):\n",
    "        if(i!=j):\n",
    "            W[i][j]=0\n",
    "X_transpose = X_train.T\n",
    "Hessian = X_transpose.dot(W.dot(X_train))\n",
    "Hessian_inv = inv(Hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods for Logistic Regression Newton's Method\n",
    "def Gradient_newton(theta, X, y):\n",
    "    m, n = X.shape\n",
    "    theta = theta.reshape((n, 1))\n",
    "    y = y.reshape((m, 1))\n",
    "    h = sigmoid(X.dot(theta))\n",
    "    return ((1 / m) * X.T.dot(h - y)) \n",
    "\n",
    "def logisticRegression_hessian(X, y,B):\n",
    "    B = B - Hessian_inv.dot(Gradient_newton(B,X,y))\n",
    "    return B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to store theta for all three class labels\n",
    "all_theta = np.zeros((3, n + 1))\n",
    "\n",
    "i = 0\n",
    "for label in class_labels:\n",
    "    #set the labels in 0 and 1\n",
    "    tmp_y = np.array(y_train == label, dtype = int)\n",
    "    optTheta = logisticRegression_hessian(X_train, tmp_y, np.zeros((n + 1,1)))\n",
    "    all_theta[i] = list(optTheta)\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate probability for each label\n",
    "P = sigmoid(X_test.dot(all_theta.T)) \n",
    "p = [class_labels[np.argmax(P[i, :])] for i in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  81.98924731182797 %\n"
     ]
    }
   ],
   "source": [
    "#Calculate accuracy of the model\n",
    "accuracy = accuracy_score(y_test,p,normalize=True, sample_weight=None) * 100\n",
    "print(\"Accuracy: \", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8357988165680473\n"
     ]
    }
   ],
   "source": [
    "#Calculate Precision of the model\n",
    "precision = precision_score(y_test,p,sample_weight=None)\n",
    "print(\"Precision: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9608843537414966\n"
     ]
    }
   ],
   "source": [
    "#Calculate recall of the model\n",
    "recall = recall_score(y_test,p,sample_weight=None)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8939873417721519\n"
     ]
    }
   ],
   "source": [
    "#Calculate F1 score of the model\n",
    "f1 = f1_score(y_test,p,sample_weight=None)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
