{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array, dot, transpose\n",
    "from numpy.linalg import inv \n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/palash/sem2/ML1/Assignment_1/Data_Q1/housing.csv\")\n",
    "df = df.drop(\"ocean_proximity\", axis=1)\n",
    "df = df.drop(\"total_bedrooms\", axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     16512.000000\n",
       "mean     207194.693738\n",
       "std      115622.626448\n",
       "min       14999.000000\n",
       "25%      119800.000000\n",
       "50%      179850.000000\n",
       "75%      265125.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set,test_set=train_test_split(df,test_size=0.2,random_state=42)\n",
    "train_y = train_set[\"median_house_value\"].copy()\n",
    "train_X = train_set.drop(\"median_house_value\", axis=1) \n",
    "test_X = test_set.drop(\"median_house_value\", axis=1) \n",
    "test_y = test_set[\"median_house_value\"].copy()\n",
    "train_X = (train_X-train_X.mean())/train_X.std()\n",
    "train_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Closed Form\n",
    "\n",
    "Closed form solution for theta is given by:\n",
    "\\begin{equation*}\n",
    "\\theta = (X^T.X)^{-1}.X^T.\\vec y\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ClosedForm(X_train, y_train):\n",
    "    X= np.array(X_train)\n",
    "    ones = np.ones(len(X))\n",
    "    X = np.column_stack((ones,X))\n",
    "    y = np.array(y_train)\n",
    "    \n",
    "    Xt = transpose(X)\n",
    "    product = dot(Xt, X)\n",
    "    theInverse = inv(product)\n",
    "    theta = dot(dot(theInverse, Xt), y)\n",
    "       \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalized_X = preprocessing.normalize(train_X)\n",
    "standardized_X = preprocessing.scale(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict labels\n",
    "test_X_n=np.c_[np.ones((4128,1)),test_X]\n",
    "theta_best = ClosedForm(standardized_X, train_y)\n",
    "predicted_labels = np.dot(test_X_n,theta_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean squared error for Closed Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3710437907436182.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Gradient Descent\n",
    "\\begin{equation*}\n",
    "J(\\theta) = (\\theta^T.X -\\vec y)^T.(\\theta^T.X -\\vec y)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta ^{new} = \\theta ^{old} - \\alpha(\\theta^T.X -\\vec y).X\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GradientDescent(x_train, y_train):\n",
    "    X = np.array(x_train)\n",
    "    ones = np.ones(len(X))\n",
    "    X = np.column_stack((ones,X))\n",
    "    y = np.array(y_train)\n",
    "    \n",
    "    m = len(y)\n",
    "    iter = 10000\n",
    "    eta=0.001\n",
    "    theta= np.zeros(8)\n",
    "    \n",
    "    for i in range (iter):\n",
    "        hypothesis = X.dot(theta)\n",
    "        error = hypothesis - y\n",
    "        gradient =  (X.T.dot(error)*2)/m\n",
    "        theta = theta - eta*gradient\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict labels\n",
    "test_X_n=np.c_[np.ones((4128,1)),test_X]\n",
    "theta_best = GradientDescent(standardized_X, train_y)\n",
    "predicted_labels = np.dot(test_X_n,theta_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean squared error for Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2058148342911836.8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Newton's Method\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta ^{new} = \\theta ^{old} - \\alpha \\dfrac{J^{'}(\\theta)} {J^{''}(\\theta)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "J^{'}(\\theta) = 2X^T(\\theta^T.X -\\vec y)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "J^{''}(\\theta) = 2X^T.X\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NewtonsMethod(x_train, y_train):\n",
    "    X = np.array(x_train)\n",
    "    ones = np.ones(len(X))\n",
    "    X = np.column_stack((ones,X))\n",
    "    y = np.array(y_train)\n",
    "    \n",
    "    m = len(y)\n",
    "    theta= np.zeros(8)\n",
    "    second_deriv = (X.T.dot(X)*2)/m\n",
    "    second_deriv = np.linalg.inv(second_deriv)\n",
    "    alpha =0.001\n",
    "    for i in range (1500):\n",
    "        hypothesis = X.dot(theta)\n",
    "        error = hypothesis - y\n",
    "        first_deriv = (X.T.dot(error)*2)/m\n",
    "        \n",
    "        theta = theta - alpha*(second_deriv.dot(first_deriv))\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict labels\n",
    "test_X_n=np.c_[np.ones((4128,1)),test_X]\n",
    "theta_best = NewtonsMethod(standardized_X, train_y)\n",
    "predicted_labels = np.dot(test_X_n,theta_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean squared error for Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2243366375420120.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y,predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Ridge Regression\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta = (X^T.X + \\lambda I_p)^{âˆ’1} X^T.\\vec y\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def ridge_regression(x_train, y_train, lam):\n",
    "    \n",
    "    X = np.array(x_train)\n",
    "    ones = np.ones(len(X))\n",
    "    X = np.column_stack((ones,X))\n",
    "    y = np.array(y_train)\n",
    "    \n",
    "    Xt = np.transpose(X)\n",
    "    lambda_identity = lam*np.identity(len(Xt))\n",
    "    theInverse = np.linalg.inv(np.dot(Xt, X)+lambda_identity)\n",
    "    w = np.dot(np.dot(theInverse, Xt), y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict labels\n",
    "test_X_n=np.c_[np.ones((4128,1)),test_X]\n",
    "theta_best = ridge_regression(standardized_X, train_y,0.001)\n",
    "predicted_labels = np.dot(test_X_n,theta_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean squared error for Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3710430984962626.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(test_y,predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
